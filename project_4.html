
<!DOCTYPE html>
<html>
	<head>
		<!-- Google tag (gtag.js) -->
<!-- 		<script async src="https://www.googletagmanager.com/gtag/js?id=G-P9JHZPCK6Q"></script>
		<script>
		  window.dataLayer = window.dataLayer || [];
		  function gtag(){dataLayer.push(arguments);}
		  gtag('js', new Date());
		
		  gtag('config', 'G-P9JHZPCK6Q');
		</script> -->
		<meta charset="UTF-8"/>
		<title>My projects</title>
		<link rel="icon" type="image/x-icon" href="img/favicon.ico">
		<meta name = "author" content = "Han Zhang"/>
		<meta name = "keywords" content = "Zhang, Han, Data analyst, Teacher, Computer, Science, Personal"/>
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=yes"/>
		<link rel = "stylesheet" href="style.css"/>
		<script src = "js/app.js"></script>
		<script type="text/javascript" src="https://webpivottable.com/releases/latest/dist/wpt.js" ></script>
	</head>

	<body>
		<div class = "container">
			<div class = "header">
				<h1>My Projects</h1>
				<h1>Mon projets</h1>
			</div>
			<br />
			<div align = "center">
				<a href = "myJob.html"> About me </a> |
				<a href = "aboutMe.html"> More about me </a> |
				<a href = "contactMe.html"> Contact </a> |
				<a href = "myProject.html"> Projects</a>
			</div>

		
		<br>
		<li><b>Job market analysis in selected Canadian cities - Beta</b> </li>
		     <br>
		     <br>
			This project aims at investigating the job supplies and categories in target cities in Canada (Sherbrooke, Montreal, Quebec City, Toronto, Vancouver, Calgary, Halifax) in a certain period. The raw data is pulled from Adzuna. It's an ongoing project, the raw data will be updated every Friday (started from 2024-11-22), 
			and it will be saved in the SQL Server on my local PC. The data will be transfered to Power BI to be analyzed and visualized. It's also a "trial and error" project, which means the algorithm will probably be adjusted and updated based on the results accordingly. Jobs will be categorized into several groups, for example, Agriculture, Customer Services, Financial Services, IT, Education, etc. (there are 30 categories in Adzuna). 
			The results will show the percentage of each category in a city, say, in the past week, among the 2000 random samples (job posts) from Montreal, 40% of the job falls into customer service; 30% falls into financial services; 20% falls into IT, etc. 
			This project is different than the <a href="project_1.html">"Top 5 companies in Canada for data analyst"</a>, where the analysis is done by the server of Adzuna, in this project all the analysis will be done by myself. Adzuna API will just supply the raw data. The following diagram shows the general procedures of this project.
		    <br><br>
			<img src="/img/job_maket_1.png" alt="work flow" width="800" height="210" class="responsive-logo"> <br>

			
			1. Extract raw data from Adzuna API by Python
			<br><br>
			The raw data will be pulled from a third-party platform – Adzuna, which is same as in the first project. <br>
			A key thing to clarify in this step is the sampling technique, it's the foundation of this project. Enough sample size will give me a good understanding of the job market with as little bias as possible. However, how much is "enough"? I don't know.
			So I'll try some small samples as a starting point at first, if the outcome is not ideal, I will adjust the sample size then repeat until I get a good response. Given the population of my target cities differ a lot, choosing a same sample size (for example 1000) will probably exhaust all job posts in that 
			period in small cities like Sherbrooke, but will be a bit small and not representitive enough for big cities like Toronto. Therefore, I will use proportional sampling technique. One thing to consider is that jobs posted in Quebec province are in French (some are in English), when parsing the website, keep an eye on some relevant keywords to see if they need to be adjusted. Here comes the detail: 
			<ol>
				<li>Set up a maximum cap for the largest city – Toronto, say 2000 job posts. (Why 2000? - as per Adzuna API, started from 2024-11-22, the total job posts of Toronto (within 30 km radius) in the past 7 days are 5197. 
				    Let's suppose Adzuna can cover all the job posts in that week in Toronto, then 5197 is the “population” in statistics from 7 days ago till that day, so 2000 sample data represents 38% of the entire jobs, which is a good enough.) In addition, this sample size would still reflect job diversity but with fewer API calls considering the tradeoff between the dada sampling and traffic on the server of Adzuna. </li><br>
				<li>Calculate the scaling factor. Say the population of Toronto city is approximately 2,794,356 according to <a href = "https://www12.statcan.gc.ca/census-recensement/2021/dp-pd/prof/details/page.cfm?Lang=E&GENDERlist=1,2,3&STATISTIClist=1,4&HEADERlist=0&DGUIDlist=2021A00053520005&SearchText=toronto" target="_blank">Statistics Canada of 2021 Census of Population</a>
				<br><br>
					<img src="/img/jm_f1.png" alt="work flow" width="400" height="110" class="responsive-logo"> 
				</li><br>
				<li>Apply this factor (f = 0.0007) to other cities to get the sample size:<br>
				Montreal, QC – 1762949 × 0.0007 ≈ 1262,<br>
				Calgary, AB – 1306784 × 0.0007 ≈ 935,<br>
				Vancouver, BC – 662248 × 0.0007 ≈ 474,<br>
				Quebec City, QC – 549459 × 0.0007 ≈ 393,<br>
				Halifax, NS – 439819 × 0.0007 ≈ 315,<br>
				Sherbrooke, QC – 172950 0.0007 ≈ 124<br>
				<br>
				let me define sample size of each city using a dictionary comprehension (for loop in key-value pair of a dictionary) <br>
<pre>
city_population = {
    'Toronto,ON': 2794356,
    'Montreal,QC': 1762949,
    'Calgary,AB': 1306784,
    'Vancouver,BC': 662248,
    'Quebec City,QC': 549459,
    'Halifax,NS': 439819,
    'Sherbrooke,QC': 172950,
}
</pre>
					<code>samples_per_city = {city: min(int(pop * scaling_factor), toronto_cap) for city, pop in city_population.items()}</code><br><br>
				the results will be like:<br>
<pre>
{'Toronto,ON': 1999,
 'Montreal,QC': 1261,
 'Calgary,AB': 935,
 'Vancouver,BC': 473,
 'Quebec City,QC': 393,
 'Halifax,NS': 314,
 'Sherbrooke,QC': 123}
</pre>
				</li><br>
				<li>Confirm page number of each city (pagination). The sample size of each city has been confirmed in previous step. However, in Adzuna API, only the data in the first page will be pulled by default, and one page can have at most 50 records, which is apparently not enough.
				So we will need to configure the "page" and “results_per_page” parameters in Adzuna. Here “page” refers to the page number, it can be integers like 1 or 2, etc.. And “results_per_page” indicates the number of job posts in one page. 
				By default, it’s 20, and the maximum number is 50. So, for a city like Toronto with sample size 2000. If I have 50 “results_per_page”, then I’ll need to pull 40 pages. (Here I can consider using a for loop in Python).  Let me generalize it as:<br>
				<br>
				<img src="/img/jm_f2.png" alt="work flow" width="300" height="110" class="responsive-logo">  <br>
				If the “results_per_page” is 50, here comes the number of pages of each city (let’s round it up):<br>
				Number of pages (Toronto) = 2000 ÷ 50 = 40, <br>
				Number of pages (Montreal) = 1262 ÷ 50 ≈ 26, <br>
				Number of pages (Calgary) = 935 ÷ 50 ≈ 19,<br>
				Number of pages (Vancouver) = 474 ÷ 50 ≈ 10,<br>
				Number of pages (Quebec City) = 393 ÷ 50 ≈ 8,<br>
				Number of pages (Halifax) = 315 ÷ 50 ≈7, <br>
				Number of pages (Sherbrooke) = 124 ÷ 50 ≈3<br>
				<br>
				For this part, a for loop will solvoe this issue. So to start up, I will get a job list of the past 7 days from 2024-11-22 as a starting point, then follow up with weekly pulls (every Friday) for ongoing data collection, which will give me some insights into how the job market evolves over time (I will have time series analysis in the future). 
				This approach avoids the heavy overhead of daily pulls but is still detailed enough to capture changes in the job market. 	
				
				</li><br>
				<li>Set up the API parameters in Python and pull the data. With those key factors confirmed in the previous steps, it's time to set up the parameters. In Aduzna, the parameters work as filters to generate the filtered results as we need, and those parameters are appended in the URL. The original URL is like: "https://api.adzuna.com/v1/api/jobs/ca/search/1?",
				    Here the “ca” represents Canada (‘country’ = ‘ca’), and “1” means the data on the first page will be pulled (‘page’ = 1). As discussed above, 1 page is not enough to get the samples, so I’ll use a for loop to pull the data on the number of pages in each city as in 1.2.  These two are obligated parameters. Other than that, we got following parameters to append after the question mark “?”:
<pre>
params = {
	    'app_id': APP_ID,
	    'app_key': APP_KEY,
	    'where': city (use a for loop to loop through ‘Toronto, Montreal, Vancouver, etc.)
	    'results_per_page': RESULTS_PER_PAGE, (here I set 50 – the max of Adzuna)
	    'max_days_old': MAX_DAYS_OLD, (since I’ll pull every week, so it’s 7)
	    'distance': DISTANCE, (it’s the distance to the city center in km, I set 30)
	    'sort_by': SORT_BY (I set sort by date – the most recent records will be put on top)
	}	
</pre>       

				   When I attach the parameters in the URL, I’ll make a request to GET the results:<br>
				   response = requests.get(api_url, params=params)<br>
				   The returned results will be in the format of JSON, I’ll need to extract the value in the ‘key’- ‘value’ pair. The outputs I will get is as following:<br>
                                   Company name ("company",{"display_name":); Job title ("title"); Job Category ("Category","label":) (such as IT/ Accounting/Financial Services, etc.); Location (province, city)("location","area":); Education (required degree, such as bachelor in computer science); contract_time (full / part time) ("contract_time"); Contract type ("contract_type"); Salary ("salary_max", "salary_min"); Publish date ("created");Description("description":)
                                   then put them into SQL Server database. So here comes the next part …

				</li>
	
			</ol>
			Here I copy & paste my code: <br><br>
			<code>
				# Created by Han Zhang (you can copy it but pls put my name on it, if it doesn't work for you, email me) <br>
				import requests<br>
				import csv<br>
				import pandas as pd<br>
				import matplotlib.pyplot as plt<br>
				APP_ID = YOUR_ID<br>
				APP_KEY = YOUR_KEY<br>
				# Define the job to search<br>
				WHAT = 'data%20analyst'<br>
				# File to store results<br>
				csv_file = 'top_companies.csv'<br>
				url = f'https://api.adzuna.com/v1/api/jobs/ca/top_companies?app_id={APP_ID}&app_key={APP_KEY}&what={WHAT}'<br>
				# Make the API request<br>
				response = requests.get(url)<br>
				if response.status_code == 200:<br>
				    data = response.json()<br>
				    # Parse JSON and extract the leaderboard data<br>
				    leaderboard = data['leaderboard']<br>
				    # Convert leaderboard data to a DataFrame<br>
				    df = pd.DataFrame(leaderboard)<br>
				    # Save the DataFrame to a CSV file<br>
				    output_file = "Top_Companies.csv"<br>
				    df.to_csv(output_file, index=False)<br>
				
				    print(f"Data saved to {output_file}")<br>
				    # plot the data in bar chart<br>
				    if not df.empty and 'canonical_name' in df and 'count' in df:<br>
					plt.figure(figsize=(10, 6))<br>
					bars = plt.barh(df['canonical_name'], df['count'], color='skyblue')<br>
				
					# Add labels and title<br>
					plt.xlabel('Count', fontsize=12)<br>
					plt.ylabel('Company Name', fontsize=12)<br>
					plt.title('Top Companies by Count of Job Vacancy (data analyst) - valide at 2024-12-10 12:55', fontsize=14)<br>
					plt.gca().invert_yaxis()  # Invert the Y-axis for better visualization<br>
					
					# Add data labels next to each bar<br>
					for bar in bars:<br>
					    width = bar.get_width()<br>
					    plt.text(width + 0.2, bar.get_y() + bar.get_height()/2, str(int(width)), <br>
						     va='center', ha='left', fontsize=10, color='black')<br>
				
					# Show the plot<br>
					plt.tight_layout()<br>
					plt.show()<br>
				    else:<br>
					print("DataFrame is empty or required columns are missing.")<br>
				else:<br>
				    print("DATA WAS NOT EXTRACTED, ERROR CODE: " & response.status_code)<br>
				
			</code>
			<br>
			Here is the result - Top 5 companies with # of vacancies for data analyst in Canada. (Please note that your result might be different than mine if you run at a different time or day.) <br><br>
			<img src="/img/Top5_companies_1.png" alt="Top 5 Companies" width="800" height="400" class="responsive-logo">
			<br>
			The result is very interesing. The top company has just less than 20 vacancies in the entire country makes me doubt it. 
			I don't know how Adzuna handles the natural language, but my experience on Google search tells me "the less key words the more results". So I just put "data" instead of "data analyst". The result proves that I was right. But that brings another problem - it' too vague. Data what? Tons of jobs are related to data. In conclusion, both are correct, if I search "apex developer for just salesforce platform", maybe I'll get 0 result. The key point is to 
			define the purpose of our analysis in advance and to find out a "tolerance point". 
			<br>
			<br>
			<img src="/img/Top5_companies_2.png" alt="Top 5 Companies" width="800" height="400" class="responsive-logo">
			<br>
			Anyway, this is a method (first step) to play the Adzuna API, it's still in a abstract level. I will dig into that to explore more.
			<br><br>
			<cite>References: <br>
				[1] Adzuna API (https://developer.adzuna.com/overview) <br>
				[2] RedHat (https://www.redhat.com/en/topics/api/what-is-a-rest-api)</cite>
							
		</div>
	</body>
</html>
